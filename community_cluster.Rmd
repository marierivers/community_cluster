---
title: "community_cluster"
author: "Marie Rivers"
date: "1/19/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```
# Clustering
## K-means Clustering
### Load and plot the `iris` dataset
```{r}
# load R packages
librarian::shelf(
  dplyr, DT, ggplot2, tibble, tidyverse)

# set seed for reproducible results
set.seed(42)

# load the dataset
data("iris")

# look at documentation in RStudio
if (interactive())
  help(iris)

# show data table
datatable(iris)
```

```{r}
# plot petal length vs. width, species naive
ggplot(
  iris, aes(Petal.Length, Petal.Width)) +
  geom_point()
```
```{r}
# plot petal length vs. width, color by species
legend_pos <- theme(
  legend.position = c(0.95, 0.05),
  legend.justification = c("right", "bottom"),
  legend.box.just = "right")

ggplot(data = iris, aes(Petal.Length, Petal.Width, color = Species)) +
  geom_point() +
  legend_pos
```
### Cluster `iris` using `kmeans()`
```{r}
# cluster using kmeans
k <- 3 # number of clusters
iris_k <- kmeans(
  iris %>% 
    select(Petal.Length, Petal.Width),
  centers = k)

# show cluster results
iris_k
```
```{r}
# compare clusters with species (which were not used to cluster)
table(iris_k$cluster, iris$Species)
```

**Question:** How many observations could be considered "misclassified" if expecting petal length and width to differentiate between species?
xxx...
```{r}
# extract cluster assignment per observation
Cluster = factor(iris_k$cluster)

ggplot(iris, aes(Petal.Length, Petal.Width, color = Cluster)) +
  geom_point() +
  legend_pos
```
### Plot Voronoi diagram of clustered `iris`
This form of clustering assigns points to the cluster based on nearest centroid. You can see breaks more clearly with a Voronoi diagram.
```{r}
librarian::shelf(ggvoronoi, scales)

# define bounding box for geom_voronoi()
box <- tribble(
  ~Petal.Length, ~Petal.Width, ~group,
  1, 0.1, 1,
  1, 2.5, 1, 
  7, 2.5, 1, 
  7, 0.1, 1, 
  1, 0.1, 1) %>% 
  data.frame()
```

```{r}
# cluster using kmeans
k <- 3 # number of clusters
iris_k <- kmeans(
  iris %>% 
    select(Petal.Length, Petal.Width),
  centers = k)
```

```{r}
# extract cluster assignment per observation
Cluster = factor(iris_k$cluster)

# extract cluster centers
ctrs <- as.data.frame(iris_k$centers) %>% 
  mutate(Cluster = factor(1:k))
```

```{r}
# plot points with voronoi diagram showing nearest centroid
ggplot(data = iris, aes(x = Petal.Length, y = Petal.Width, color = Cluster)) +
  geom_point() +
  legend_pos +
  geom_voronoi(data = ctrs, aes(fill = Cluster), color = NA, alpha = 0.5, outline = box) +
  geom_point(data = ctrs, pch = 23, cex = 2, fill = "black")

```

Task: Show the Voronoi diagram for fewer (k=2) and more (k=8) clusters to see how assignment to cluster centroids work.
xxx
## Hierarchical Clustering
Next, cluster sites according to species composition. Use the dune dataset from the vegan R package.

### Load `dune` dataset
```{r}
librarian::shelf(cluster, vegan)

# load dune dataset from package vegan
data("dune")

# show documentation on dataset if interactive
if (interactive())
  help(dune)
```

**Question:** What are the rows and columns composed of in the dune data frame?
xxx

### Calculate Ecological Distances on `sites`
```{r}
sites <- tribble(
  ~site, ~sp1, ~sp2, ~sp3,
  "A", 1, 1, 0,
  "B", 5, 5, 0,
  "C", 0, 0, 1) %>% 
  column_to_rownames("site")
sites
```

```{r}
sites_manhattan <- vegdist(sites, method = "manhattan")
sites_manhattan
```

```{r}
sites_euclidean <- vegdist(sites, method = "euclidean")
sites_euclidean
```

```{r}
sites_bray <- vegdist(sites, method = "bray")
sites_bray
```

### Bray-Curtis Dissimilarity on `sites`
xxx...do we calcusate these values in R?

### Agglomerative hierarchical clustering on `dune`
```{r}
# Dissimilarity matrix
d <- vegdist(dune, method = "bray")
dim(d)

as.matrix(d)[1:5, 1:5]
```

```{r}
# Hierarchical clustering using Complete Linkage
hc1 <- hclust(d, method = "complete")

# Dendrogram plot of hc1
plot(hc1, cex = 0.6, hang = -1)
```

```{r}
# Compute agglomerative clustering with agnes
hc2 <- agnes(dune, method = "complete")

# Agglomerative coefficient
hc2$ac
```

```{r}
# Dendrogram plot of hc2
plot(hc2, which.plots = 2)
```

```{r}
# method to assess
m <- c("average", "single", "complete", "ward")
names(m) <- c("average", "single", "complete", "ward")

# function to compute coefficient
ac <- function(x) {
  agnes(dune, method = x)$ac
}

# get agglomerative coefficient for each linkage method
purrr::map_dbl(m, ac)
```

```{r}
# compute ward linkage clustering with agnes
hc3 <- agnes(dune, method = "ward")

# Agglomerative coefficient
hc3$ac
```

```{r}
# Dendrogram plot of hc3
plot(hc3, which.plots = 2)
```

### Divisive hierarchical clustering on `dune`
```{r}
# compute divisive hierarchical clustering
hc4 <- diana(dune)

# Divise coefficient; amount of clustering structure found
hc4$dc
```

### Determining optimal clusters
```{r}
librarian::shelf(factoextra)
```

```{r}
# Plot cluster results
p1 <- fviz_nbclust(dune, FUN = hcut, method = "wss", k.max = 10) +
  ggtitle("(A) Elbow method")

p2 <- fviz_nbclust(dune, FUN = hcut, method = "silhouette", k.max = 10) +
  ggtitle("(B) Silhouette method")

p3 <- fviz_nbclust(dune, FUN = hcut, method = "gap_stat", k.max = 10) +
  ggtitle("(C) Gap statistic")

# display plots side by side
gridExtra::grid.arrange(p1, p2, p3, nrow = 1)

```

### Working with dendrograms

```{r}
# Construct dendrogram for the Ames housing example
hc5 <- hclust(d, method = "ward.D2")
dend_plot <- fviz_dend(hc5)
dend_data <- attr(dend_plot, "dendrogram")
dend_cuts <- cut(dend_data, h = 8)
fviz_dend(dend_cuts$lower[[2]])
```

```{r}
# Ward's method
hc5 <- hclust(d, method = "ward.D2")

# Cut tree into 4 groups
k = 4
sub_grp <- cutree(hc5, k = k)

# Number of members in each cluster
table(sub_grp)
```

```{r}
# Plot full dendrogram
fviz_dend(
  hc5, 
  k = k, 
  horiz = TRUE,
  rect = TRUE,
  rect_fill = TRUE,
  rect_border = "jco",
  k_colors = "jco")
```

# 2b. Community - Cluster
# Ordination
## Principal Component Analysis (PCA)

```{r}
# load R packages
librarian::shelf(dplyr, ggplot2, h2o)

# set seed for reproducible results
set.seed(42)

# get data
url <- "https://koalaverse.github.io/homlr/data/my_basket.csv"
my_basket <- readr::read_csv(url)
dim(my_basket)
```

### Performing PCA in R
```{r}
h2o.no_progress() # turn off progress bars for brevity
h2o.init(max_mem_size = "5g") # connect to H2O instance
```

```{r}
# convert data to h2o object
my_basket.h2o <- as.h2o(my_basket)
```
```{r}
# run PCA
my_pca <- h2o.prcomp(
  training_frame = my_basket.h2o,
  pca_method = "GramSVD",
  k = ncol(my_basket.h2o),
  transform = "STANDARDIZE",
  impute_missing = TRUE,
  max_runtime_secs = 1000)
my_pca
```

```{r}
my_pca@model$eigenvectors %>% 
  as.data.frame() %>% 
  mutate(feature = row.names(.)) %>% 
  ggplot(aes(pc1, reorder(feature, pc1))) +
  geom_point()
```

```{r}
# xxx, typo here???
my_pca@model$eigenvectors %>% 
  as.data.frame() %>% 
  mutate(feature = row.names(.)) %>% 
  ggplot(aes(pc1, pc2, label = feature)) +
  geom_text()
```

### Eigenvalue criterion
```{r}
# Compute eigenvalues
eigen <- my_pca@model$importance["Standard deviation", ] %>% 
  as.vector() %>% 
  .^2

# sum of all eigenvalues equals number of variables
```

```{r}
# Find PCs where the sum of eigenvalues is greater than or equal to 1
which(eigen >= 1)
```

```{r}
# Extract PVE and CVE
ve <- data.frame(
  PC = my_pca@model$importance %>% seq_along(),
  PVE = my_pca@model$importance %>%  .[2, ] %>%  unlist(),
  CVE = my_pca@model$importance %>% .[3, ] %>%  unlist())
```

```{r}
# Plot PVE and CVE
ve %>% 
  tidyr::gather(metric, variance_explained, -PC) %>% 
  ggplot(aes(PC, variance_explained)) +
  geom_point() +
  facet_wrap(~ metric, ncol = 1, scales = "free")
```

```{r}
# How many PCs required to explain at least 75% of total variable
min(which(ve$CVE >= 0.75))
```

```{r}
# Screee plot criterion
data.frame(
  PC = my_pca@model$importance %>% seq_along,
  PVE = my_pca@model$importance %>%  .[2, ] %>%  unlist()) %>% 
  ggplot(aes(PC, PVE, group = 1, label = PC)) +
  geom_point() +
  geom_line() +
  geom_text(nudge_y = -.002)
```

## Non-metric MultiDimensional Scaling (NMDS)
### Unconstrained Ordination on Species
```{r}
# load R packages
librarian::shelf(vegan, vegan3d)

# vegetation and environment inlichen pastures from Vare et al (1995)
data("varespec") # species
data("varechem") # chemistry

varespec %>% tibble()
```

```{r}
vare.dis <- vegdist(varespec)
vare.mds0 <- monoMDS(vare.dis)
stressplot(vare.mds0)
```

```{r}
ordiplot(vare.mds0, type = "t")
```

```{r}
vare.mds <- metaMDS(varespec, trace= FALSE)
vare.mds
```
```{r}
plot(vare.mds, type = "t")
```

### Overlay with Environment
```{r}
ef <- envfit(vare.mds, varechem, permu = 999)
ef
```

```{r}
plot(vare.mds, display = "sites")
plot(ef, p.max = 0.05)
```

```{r}
ef <- envfit(vare.mds ~ Al + Ca, data = varechem)
plot(vare.mds, display = "sites")
plot(ef)

tmp <- with(varechem, ordisurf(vare.mds, Al, add = TRUE))
ordisurf(vare.mds ~ Ca, data = varechem, add = TRUE, col = "green4")
```

```{r}

```

### Constrained Ordination on Species and Environment
```{r}
# ordinate on species constrained by three soil elements
vare.cca <- cca(varespec ~ Al + P + K, varechem)
vare.cca
```

```{r}
# plot ordination
plot(vare.cca)
```

```{r}
# plot 3 dimensions
ordiplot3d(vare.cca, type = "h")
```

```{r}
if (interactive()){
  ordirgl(vare.cca)
}
```


